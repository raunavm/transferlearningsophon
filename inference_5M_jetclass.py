import os
import sys
import csv
import math
import torch
import uproot
import numpy as np
from tqdm import tqdm
from math import cos, sin, sinh

sys.path.append(".")
from networks.example_ParticleTransformer_sophon import get_model


TARGET_EVENTS = 5_000_000
MAX_PART = 128
STEP_SIZE = 5000
TREE_NAME = "tree"

root_dir = "../data/JetClass/val_5M"
root_files = [
    "HToCC_120.root", "HToCC_121.root",
    "HToCC_122.root", "HToCC_123.root", "HToCC_124.root"
]
OUTPUT_CSV = "inference_5M_with_embedding.csv"

particle_keys = [
    'part_px', 'part_py', 'part_pz', 'part_energy',
    'part_deta', 'part_dphi', 'part_d0val', 'part_d0err',
    'part_dzval', 'part_dzerr', 'part_charge',
    'part_isChargedHadron', 'part_isNeutralHadron',
    'part_isPhoton', 'part_isElectron', 'part_isMuon'
]
scalar_keys = [
    'label_QCD','label_Hbb','label_Hcc','label_Hgg',
    'label_H4q','label_Hqql','label_Zqq','label_Wqq',
    'label_Tbqq','label_Tbl','jet_pt','jet_eta','jet_phi',
    'jet_energy','jet_nparticles','jet_sdmass','jet_tau1',
    'jet_tau2','jet_tau3','jet_tau4','aux_genpart_eta',
    'aux_genpart_phi','aux_genpart_pid','aux_genpart_pt',
    'aux_truth_match'
]
pf_keys = particle_keys + scalar_keys

label_names = [
    "QCD","Hbb","Hcc","Hgg","Htoww4q",
    "Hqql","Zqq","Znn","Htoww2q1L","Ttbar", "Ttbarlep"
]


class DummyDataConfig:
    input_dicts = {"pf_features": list(range(37))}
    input_names = ["pf_points"]
    input_shapes = {"pf_points": (MAX_PART, 37)}
    label_names = ["label"]
    num_classes = 10

data_config = DummyDataConfig()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model, _ = get_model(data_config, num_classes=data_config.num_classes, export_embed=True)
model.eval().to(device)


def build_pf_tensor(arrays, i):
    """Return model inputs for event i, or None if too many particles."""
    n_part = arrays["part_px"][i].shape[0]
    if n_part > MAX_PART:
        return None

    particle_feats = [arrays[k][i] for k in particle_keys]
    scalar_feats = [np.full(n_part, arrays[k][i]) for k in scalar_keys]
    all_feats = particle_feats + scalar_feats

    pf_features = np.stack(all_feats, axis=1).astype(np.float32)

    padded = np.zeros((MAX_PART, pf_features.shape[1]), dtype=np.float32)
    padded[:n_part, :] = pf_features

    jet_tensor = torch.tensor(padded, dtype=torch.float32).unsqueeze(0).to(device)
    lorentz_vectors = jet_tensor[:, :, 0:4].transpose(1, 2)
    features = jet_tensor[:, :, 4:].transpose(1, 2)
    mask = (jet_tensor.sum(dim=2) != 0).unsqueeze(1)
    points = None
    return points, features, lorentz_vectors, mask


def get_truth_label(arrays, i):
    labs = np.array([arrays[k][i] for k in [
        'label_QCD','label_Hbb','label_Hcc','label_Hgg',
        'label_H4q','label_Hqql','label_Zqq','label_Wqq',
        'label_Tbqq','label_Tbl'
    ]])
    y = int(np.argmax(labs))
    # guard against label_names being longer than labs
    y = min(y, len(label_names) - 1)
    return y, label_names[y]


def jet_masses(arrays, i):
    jet_sdmass = float(arrays["jet_sdmass"][i])
    pt  = float(arrays["jet_pt"][i])
    eta = float(arrays["jet_eta"][i])
    phi = float(arrays["jet_phi"][i])
    E   = float(arrays["jet_energy"][i])

    px = pt * cos(phi)
    py = pt * sin(phi)
    pz = pt * sinh(eta)
    m2 = max(E*E - (px*px + py*py + pz*pz), 0.0)

    return jet_sdmass, math.sqrt(m2), pt, eta, phi


def main():
    os.makedirs(os.path.dirname(OUTPUT_CSV) or ".", exist_ok=True)
    total_written, wrote_header = 0, False

    with open(OUTPUT_CSV, "w", newline="") as csvfile:
        writer = csv.writer(csvfile)

        paths = [f"{os.path.join(root_dir, fn)}:{TREE_NAME}" for fn in root_files]
        it = uproot.iterate(
            paths,
            expressions=pf_keys,
            entry_step=STEP_SIZE,
            library="np"
        )

        for batch_idx, arrays in enumerate(it):
            batch_len = len(arrays["jet_pt"])
            pbar = tqdm(range(batch_len), desc=f"batch {batch_idx}")

            for i in pbar:
                if total_written >= TARGET_EVENTS:
                    break
                try:
                    built = build_pf_tensor(arrays, i)
                    if built is None:
                        continue

                    points, features, lorentz_vectors, mask = built

                    with torch.no_grad():
                        out = model(points, features, lorentz_vectors, mask)

                    # fix to handle both (logits, embedding) and embedding-only
                    if isinstance(out, tuple):
                        logits, embedding = out
                    else:
                        logits, embedding = None, out

                    emb = embedding.squeeze(0).detach().cpu().numpy()

                    if not wrote_header:
                        base = [
                            "file", "global_index", "truth_label", "label_name",
                            "jet_sdmass", "jet_mass", "jet_pt", "jet_eta", "jet_phi"
                        ]
                        emb_cols = [f"emb_{j}" for j in range(emb.shape[-1])]
                        writer.writerow(base + emb_cols)
                        wrote_header = True

                    truth_label, label_name = get_truth_label(arrays, i)
                    jet_sdmass, jet_mass, pt, eta, phi = jet_masses(arrays, i)

                    row = [
                        "HToCC_*",
                        total_written,
                        truth_label,
                        label_name,
                        jet_sdmass,
                        jet_mass,
                        pt,
                        eta,
                        phi,
                    ] + list(emb.astype(np.float32))

                    writer.writerow(row)
                    total_written += 1

                except Exception as e:
                    pbar.set_postfix_str(f"err: {e}")
                    continue

            if total_written >= TARGET_EVENTS:
                break

    print(f"\nâœ… Saved {total_written:,} rows to {OUTPUT_CSV}")


if __name__ == "__main__":
    main()
